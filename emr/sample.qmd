---
title: "AWP_FL_GA_Voter_Detail"
author: "Jerome Dixon"
date: "6/17/2022"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(cache = TRUE, warning=FALSE, message=FALSE, eval = FALSE, echo = TRUE)

```

```{r}

Sys.setenv("TZ" = "EST")
Sys.setenv("ARROW_DEPENDENCY_SOURCE" = "BUNDLED")
Sys.setenv("NOT_CRAN" = TRUE)

source("https://raw.githubusercontent.com/apache/arrow/master/r/R/install-arrow.R")

```

  
```{r Load-Libraries, results='hide'}

library(readr)
library(sparklyr)
library(dplyr)
library(magrittr)
library(ggplot2)
library(tidyverse)
library(stringr)
library(here)
library(aws.s3)
library(aws.signature)
library(jsonlite)
library(scales)
library(stringi)
library(kableExtra)

```


# AWS EMR Mode

```{r start-spark-session, echo=TRUE}

# Configure Cluster / Start Session
conf <- spark_config()
sc <- spark_connect(master = "yarn", version = "3.1.2")

```

# Output Folders
s3://awp-data-lake/pool-cleaned/csv/clients/
s3://awp-data-lake/pool-cleaned/csv/source_db/


# FL_GA Input Files
s3://awp-data-lake/awp-data-pool/FL_GA/FL_Data.csv
s3://awp-data-lake/awp-data-pool/FL_GA/FL_GA_Data.csv
s3://awp-data-lake/awp-data-pool/FL_GA/GA_Data.csv

```{r load-fl-ga}

#### FL_GA Voter Detail

fl_ga_folder_files  <-"s3://awp-data-lake/awp-data-pool/csv/FL_GA/"

# Read files into Spark dataframe
fl_ga  <- spark_read_csv(sc, name = "FL_GA", path=fl_ga_folder_files, infer_schema = TRUE, header = F, delimiter = "\t")





# Create dplyr reference to Spark dataframe
fl_ga <- tbl(sc, 'fl_ga')

```


```{r data-prep-fl-ga}

fl_ga_clients <- fl_ga %>% 
  dplyr::select(1,2,3,4) %>% 
  mutate(DB_Source="fl_ga",
         Client_ID = tolower(paste( "fl_ga", 
                                       substr(Name,1,3) , 
                                       substr(Address,1,3),
                                       sep = "_"))
         ) %>% 
  dplyr::select(Client_ID, Name, Address, DB_Source) %>% 
  sdf_register("fl_ga_db")



spark_write_csv(fl_ga_clients, path = 's3://awp-data-lake/pool-cleaned/csv/clients/fl_ga', mode = "overwrite", skipNul = TRUE)

spark_write_csv(fl_ga, path = 's3://awp-data-lake/pool-cleaned/csv/source_db/fl_ga', mode = "overwrite", skipNul = TRUE)


```


```{r load-voter-detail}

#### FL_GA Voter Detail

fl_ga_voter_folder_files  <-"s3://awp-data-lake/awp-data-pool/FL_VOTER/Voter_Detail/"

# Read files into Spark dataframe
voter_detail  <- spark_read_csv(sc, name = "VOTER_DETAIL", path=fl_ga_voter_folder_files, infer_schema = TRUE, header = F, delimiter = "\t")


# Cache table into memory and create dplyr reference to Spark dataframe
tbl_cache(sc, 'voter_detail')
voter_detail <- tbl(sc, 'voter_detail')

```


```{r data-prep-voter-detail}

fl_voter <- voter_detail %>% 
  dplyr::select(1,3,5,6,8,9,10,12,20,22,23,24,38) %>% 
  unite("name1", c("V5","V6","V3"), sep = " ", remove = TRUE, na.rm = TRUE) %>% 
  mutate(Zip_Code = substr(V12,1,5)) %>% 
  unite("address", V8:V12, sep = " ", remove = TRUE, na.rm = TRUE) %>% 
  mutate(name = regexp_replace(name1, "  +"," ")) %>%
  mutate(County = v1,
         gender = V20,
         email = tolower(V38),
         bday = V22,
         date_ = V23,
         Address = toupper(address),
         Name= toupper(name1),
         party_affiliation = toupper(v24),
         DB_Source="fl_voter",
         Client_ID = tolower(paste( "fl_voter", 
                                       substr(name1,1,3) , 
                                       substr(address,1,3),
                                       sep = "_"))
         ) %>% 
  dplyr::select(County, Client_ID, Name, Address, Zip_Code, gender, bday, date_, email, party_affiliation, DB_Source) %>% 
  dplyr::filter(!grepl('\\\\*', Name)) %>% 
  mutate(Client_ID = regexp_replace(Client_ID, " ", "_")) %>% 
  mutate(Address = regexp_replace(Address, "  +", " ")) %>%
  sdf_register("fl_voter")


fl_voter_clients <- fl_voter |> 
  dplyr::select(4,1,2,3) 


spark_write_csv(fl_voter, path = 's3://awp-data-lake/pool-cleaned/csv/source_db/fl_voter', mode = "overwrite", skipNul = TRUE)

spark_write_csv(fl_voter_clients, path = 's3://awp-data-lake/pool-cleaned/csv/clients/fl_voter', mode = "overwrite", skipNul = TRUE)

```



```{r render-markdown, include=FALSE}

rmarkdown::render("awp_preprocess_fl_ga_voter_emr.Rmd")

```


```{sh update-EDA-script, include=TRUE, eval=TRUE}

# Copies EDA to EMR Setup Bootstrap Script For Next EMR Cluster Build
aws s3 cp 'awp_preprocess_fl_ga_voter_emr.Rmd' s3://awp-data-eda/code/awp_preprocess_fl_ga_voter_emr.Rmd | tee


```


```{sh Copy-Render, include=TRUE, eval=TRUE}

# Copies EDA html output to folder for sharing analysis
aws s3 cp 'awp_preprocess_fl_ga_voter_emr.html' s3://awp-data-eda/eda-website/ | tee

```

