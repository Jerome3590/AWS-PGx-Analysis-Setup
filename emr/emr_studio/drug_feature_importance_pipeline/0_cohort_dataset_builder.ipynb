{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d5dedf-e7c6-476d-a86e-34eb13b5f870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T16:04:11.141330Z",
     "iopub.status.busy": "2024-12-17T16:04:11.140788Z",
     "iopub.status.idle": "2024-12-17T16:04:11.159038Z",
     "shell.execute_reply": "2024-12-17T16:04:11.158358Z",
     "shell.execute_reply.started": "2024-12-17T16:04:11.141294Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.jars.packages': 'ai.catboost:catboost-spark_3.5_2.12:1.2.7', 'spark.executor.memory': '24g', 'spark.executor.cores': '4', 'spark.driver.memory': '24g', 'spark.yarn.am.memory': '4g', 'spark.dynamicAllocation.enabled': 'true', 'spark.task.cpus': '4', 'spark.jars.packages.resolve.transitive': 'true', 'spark.executor.extraJavaOptions': '--add-exports java.base/sun.net.util=ALL-UNNAMED', 'spark.driver.extraJavaOptions': '--add-exports java.base/sun.net.util=ALL-UNNAMED', 'spark.network.timeout': '1200s', 'spark.rpc.askTimeout': '1200s', 'spark.executor.memoryOverhead': '4g'}, 'proxyUser': 'assumed-role_EMRStudio_User_Role_jdixon3590', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.jars.packages\": \"ai.catboost:catboost-spark_3.5_2.12:1.2.7\",\n",
    "        \"spark.executor.memory\": \"24g\",\n",
    "        \"spark.executor.cores\": \"4\",       \n",
    "        \"spark.driver.memory\": \"24g\",      \n",
    "        \"spark.yarn.am.memory\": \"4g\",     \n",
    "        \"spark.dynamicAllocation.enabled\": \"true\", \n",
    "        \"spark.task.cpus\": \"4\",          \n",
    "        \"spark.jars.packages.resolve.transitive\": \"true\",\n",
    "        \"spark.executor.extraJavaOptions\": \"--add-exports java.base/sun.net.util=ALL-UNNAMED\",\n",
    "        \"spark.driver.extraJavaOptions\": \"--add-exports java.base/sun.net.util=ALL-UNNAMED\",\n",
    "        \"spark.network.timeout\": \"1200s\",  \n",
    "        \"spark.rpc.askTimeout\": \"1200s\", \n",
    "        \"spark.executor.memoryOverhead\": \"4g\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba04fa74-e410-455e-ba84-919cbeefe66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T16:04:17.643538Z",
     "iopub.status.busy": "2024-12-17T16:04:17.643297Z",
     "iopub.status.idle": "2024-12-17T16:05:10.212040Z",
     "shell.execute_reply": "2024-12-17T16:05:10.211185Z",
     "shell.execute_reply.started": "2024-12-17T16:04:17.643510Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bc8697ed9f45f2a21b3932aec9e4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody><tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1734450172449_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-3-111.ec2.internal:20888/proxy/application_1734450172449_0002/\" class=\"emr-proxy-link j-1KTDC0ELEZ3SI application_1734450172449_0002\" emr-resource=\"j-1KTDC0ELEZ3SI\n",
       "\" application-id=\"application_1734450172449_0002\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-15-210.ec2.internal:8042/node/containerlogs/container_1734450172449_0002_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494463b87c034220991ee899d6b35377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856ee6c6e235411eb9c3b794585d47f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
    "import catboost_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef83f3-7573-4ed1-98d0-601c881c4d2d",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Adding a parameter tag\n",
    "cohort = 'cohort1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "412df372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T15:56:37.688478Z",
     "iopub.status.busy": "2024-12-17T15:56:37.688241Z",
     "iopub.status.idle": "2024-12-17T15:56:49.080154Z",
     "shell.execute_reply": "2024-12-17T15:56:49.079435Z",
     "shell.execute_reply.started": "2024-12-17T15:56:37.688450Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fb33a85ddd4ee4bfc7820353efa7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbff9baf90054b57ae87d9e7fd972db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train and test datasets...\n",
      "Train and test datasets successfully loaded."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import ai.catboost.spark as catboost_spark\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# S3 Paths\n",
    "s3_bucket = \"s3://pgx-repository/ade-risk-model/Step5_Time_to_Event_Model/2_processed_datasets/{cohort}\"\n",
    "train_input_path = f\"{s3_bucket}/train\"\n",
    "test_input_path = f\"{s3_bucket}/test\"\n",
    "\n",
    "# Read processed train and test datasets from S3\n",
    "print(\"Reading train and test datasets...\")\n",
    "train_df = spark.read.parquet(train_input_path)\n",
    "test_df = spark.read.parquet(test_input_path)\n",
    "\n",
    "print(\"Train and test datasets successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48acbb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Add \"Hospitalization\" column\n",
    "events_df = events_df.withColumn(\"Hospitalization\", F.lit(1).cast(IntegerType()))\n",
    "non_events_df = non_events_df.withColumn(\"Hospitalization\", F.lit(0).cast(IntegerType()))\n",
    "\n",
    "# Sample and Balance the Dataset\n",
    "hosp_1_df = events_df.sample(withReplacement=False, fraction=0.5, seed=42)\n",
    "hosp_0_df = non_events_df.sample(withReplacement=False, fraction=0.1, seed=42)\n",
    "\n",
    "# Combine Events and Non-Events\n",
    "combined_df = hosp_1_df.union(hosp_0_df)\n",
    "\n",
    "# Show combined data\n",
    "print(\"Combined Dataset:\")\n",
    "combined_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae342bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = combined_df.orderBy(col(\"mi_person_key\").asc(), col(\"drug_date\").asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "unique_levels = sorted_df.groupBy(\"drug_name\").count()\n",
    "unique_levels.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace, when, expr\n",
    "\n",
    "# Function to alphabetically sort drug combinations\n",
    "def sort_combination(drug_name):\n",
    "    parts = drug_name.split('+')\n",
    "    return '+'.join(sorted(parts))\n",
    "\n",
    "# Register the UDF\n",
    "spark.udf.register(\"sort_combination\", sort_combination, StringType())\n",
    "\n",
    "# Standardize drug names\n",
    "clean_df = sorted_df.withColumn(\n",
    "    'standardized_drug_name',\n",
    "    lower(col('drug_name'))\n",
    ")\n",
    "\n",
    "# Remove trailing slashes using regexp_replace\n",
    "clean_df = clean_df.withColumn('standardized_drug_name', \n",
    "    regexp_replace(col('standardized_drug_name'), '/$', ''))\n",
    "\n",
    "# Replace spaces with underscores\n",
    "clean_df = clean_df.withColumn(\n",
    "    'standardized_drug_name',\n",
    "    regexp_replace(col('standardized_drug_name'), ' ', '_')\n",
    ")\n",
    "\n",
    "# Replace '/' with '+'\n",
    "clean_df = clean_df.withColumn(\n",
    "    'standardized_drug_name',\n",
    "    regexp_replace(col('standardized_drug_name'), '/', '+')\n",
    ")\n",
    "\n",
    "# Sort combinations if they contain '+'\n",
    "clean_df = clean_df.withColumn(\n",
    "    'standardized_drug_name',\n",
    "    when(col('standardized_drug_name').contains('+'),\n",
    "         expr('sort_combination(standardized_drug_name)'))\n",
    "    .otherwise(col('standardized_drug_name'))\n",
    ")\n",
    "\n",
    "# Handle Non Drug Items\n",
    "medical_supplies = [\n",
    "    'accu-chek', 'knee_brace', 'lancet', 'syringe', 'needle', 'test_strip', 'monitor',\n",
    "    'lancing_device', 'insulin_pump', 'glucose_meter', 'blood_glucose', 'nebulizer',\n",
    "    'inhaler', 'spacer', 'chamber', 'compressor', 'catheter', 'dressing', 'bandage',\n",
    "    'gauze', 'tape', 'alcohol_prep', 'alcohol_swab', 'pen_needle', 'aerochamber', 'onetouch',\n",
    "    'optichamber'\n",
    "]\n",
    "\n",
    "# Filter out medical supplies and mark as 'not_drug'\n",
    "for item in medical_supplies:\n",
    "    clean_df = clean_df.withColumn('standardized_drug_name',\n",
    "        when(col('standardized_drug_name').contains(item), 'not_drug')\n",
    "        .otherwise(col('standardized_drug_name'))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import create_map, lit, coalesce, col\n",
    "\n",
    "# Function to apply a mapping\n",
    "def replace_values_with_mapping(df, column_name, mapping):\n",
    "    mapping_expr = create_map([lit(x) for pair in mapping.items() for x in pair])\n",
    "    return df.withColumn(column_name, coalesce(mapping_expr[col(column_name)], col(column_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5901b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidations\n",
    "\n",
    "consolidations_a = {\n",
    "    'thioridazine_hcl': 'thioridazine',\n",
    "    'miconazole_nitrate': 'miconazole',\n",
    "    'almotriptan_malate': 'almotriptan',\n",
    "    'alogliptin/metformin_hcl': 'alogliptin+metformin',\n",
    "    'alogliptin/pioglitazone': 'alogliptin+pioglitazone',\n",
    "    'cvs_nicotine_polacrilex': 'nicotine',\n",
    "    'metformin_hydrochloride': 'metformin',\n",
    "    'rizatriptan_benzoate_odt': 'rizatriptan',\n",
    "    'warfarin_sodium': 'warfarin',\n",
    "    'buprenorphine_hcl': 'buprenorphine',\n",
    "    'butalbital+acetaminophen': 'acetaminophen+butalbital',\n",
    "    'cvs_acetaminophen': 'acetaminophen',\n",
    "    'zolpidem_tartrate': 'zolpidem',\n",
    "    'acetaminophen_childrens': 'acetaminophen+childrens',\n",
    "    'acetaminophen_er': 'acetaminophen+er',\n",
    "    'acetaminophen_extra_stren': 'acetaminophen+extra_strength',\n",
    "    'acetaminophen_pm_extra_st': 'acetaminophen+pm+extra_strength',\n",
    "    'acetaminophen+caffeine+di': 'acetaminophen+caffeine+diphenhydramine',\n",
    "    'acetaminophen+codeine': 'acetaminophen+codeine',\n",
    "    'acetaminophen+codeine_pho': 'acetaminophen+codeine+phosphate',\n",
    "    'acetaminophen+diphenhydra': 'acetaminophen+diphenhydramine',\n",
    "    'acebutolol_hcl': 'acebutolol',\n",
    "    'acebutolol_hydrochloride': 'acebutolol',\n",
    "    'acebutolol+hydrochloride': 'acebutolol',\n",
    "    'acetazolamide_er': 'acetazolamide+er',\n",
    "    'acetic_acid_0.25%': 'acetic_acid',\n",
    "    'acetic_acid+aluminum_acet': 'acetic_acid+aluminum_acetate',\n",
    "    'acetic_acid+hydrocortison': 'acetic_acid+hydrocortisone',\n",
    "    \n",
    "    # Aspirin\n",
    "    'acetylsalicylic_acid': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid_81': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid_81_low_dose': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid_adult': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid_adult_low_dose': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid_adult_low_strengt': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid_childrens': 'acetylsalicylic_acid+childrens',\n",
    "    'acetylsalicylic_acid_ec': 'acetylsalicylic_acid+ec',\n",
    "    'acetylsalicylic_acid_ec_lo-dose': 'acetylsalicylic_acid+ec',\n",
    "    'acetylsalicylic_acid_ec_low_dose': 'acetylsalicylic_acid+ec',\n",
    "    'acetylsalicylic_acid_enteric_coated_ad': 'acetylsalicylic_acid+ec',\n",
    "    'acetylsalicylic_acid_low_dose': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid_low_strength': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid_regular_strength': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acidir-low': 'acetylsalicylic_acid',\n",
    "    'acetylsalicylic_acid+dipyridamole': 'acetylsalicylic_acid+dipyridamole',\n",
    "    'acetylsalicylic_acid+dipyridamole_er': 'acetylsalicylic_acid+dipyridamole+er',\n",
    "    'acetylsalicylic_acidercreme': 'acetylsalicylic_acid+topical',\n",
    "    'acetylsalicylic_acidercreme+aloe': 'acetylsalicylic_acid+aloe+topical',\n",
    "    'acetylsalicylic_acidercreme_lidocaine': 'acetylsalicylic_acid+lidocaine+topical',\n",
    "    'acetylsalicylic_acidercreme_lidocaine_max': 'acetylsalicylic_acid+lidocaine+max+topical',\n",
    "    'acetylsalicylic_acidercreme_lidocaine_patc': 'acetylsalicylic_acid+lidocaine+patch+topical',\n",
    "    'acetylsalicylic_acidercreme_max_roll-on_ar': 'acetylsalicylic_acid+max+roll_on+topical',\n",
    "    'acetylsalicylic_acidercreme_w+lidocaine': 'acetylsalicylic_acid+lidocaine+topical',\n",
    "    'aspir-low': 'acetylsalicylic_acid',\n",
    "    'aspirin': 'acetylsalicylic_acid',\n",
    "    'aspirin_81': 'acetylsalicylic_acid',\n",
    "    'aspirin_81_low_dose': 'acetylsalicylic_acid',\n",
    "    'aspirin_adult': 'acetylsalicylic_acid',\n",
    "    'aspirin_adult_low_dose': 'acetylsalicylic_acid',\n",
    "    'aspirin_adult_low_strengt': 'acetylsalicylic_acid',\n",
    "    'aspirin_child': 'acetylsalicylic_acid+childrens',\n",
    "    'aspirin_childrens': 'acetylsalicylic_acid+childrens',\n",
    "    'aspirin_ec': 'acetylsalicylic_acid+ec',\n",
    "    'aspirin_ec_lo-dose': 'acetylsalicylic_acid+ec',\n",
    "    'aspirin_ec_low_dose': 'acetylsalicylic_acid+ec',\n",
    "    'aspirin_enteric_coated_ad': 'acetylsalicylic_acid+ec',\n",
    "    'aspirin_low_dose': 'acetylsalicylic_acid',\n",
    "    'aspirin_low_strength': 'acetylsalicylic_acid',\n",
    "    'aspirin_regular_strength': 'acetylsalicylic_acid',\n",
    "    'aspirin+dipyridamole': 'acetylsalicylic_acid+dipyridamole',\n",
    "    'aspirin+dipyridamole_er': 'acetylsalicylic_acid+dipyridamole+er',\n",
    "    \n",
    "    # Afluria (Seasonal)\n",
    "    'afluria_2014-2015': 'afluria',\n",
    "    'afluria_2016-2017': 'afluria',\n",
    "    'afluria_2017-2018': 'afluria',\n",
    "\n",
    "    # Afluria PF (Preservative-Free)\n",
    "    'afluria_pf_2015-2016': 'afluria_pf',\n",
    "    'afluria_pf_2016-2017': 'afluria_pf',\n",
    "    'afluria_pf_2017-2018': 'afluria_pf',\n",
    "    'afluria_pf_2018-2019': 'afluria_pf',\n",
    "\n",
    "    # Afluria Quadrivalent\n",
    "    'afluria_quadrivalent_2017': 'afluria_quadrivalent',\n",
    "    'afluria_quadrivalent_2018': 'afluria_quadrivalent',\n",
    "    'afluria_quadrivalent_2019': 'afluria_quadrivalent',\n",
    "    'afluria_quadrivalent_2020': 'afluria_quadrivalent',\n",
    "    \n",
    "    # Albuterol\n",
    "    'albuterol_sulfate': 'albuterol',\n",
    "    'albuterol_sulfate_er': 'albuterol+er',\n",
    "    'albuterol_sulfate_hfa': 'albuterol+hfa',\n",
    "    \n",
    "    # Additional 'A' drugs\n",
    "    'allegra-d_12_hour': 'allegra-d+12_hour',\n",
    "    'allegra-d_12_hour_allergen': 'allegra-d+12_hour',\n",
    "    'allegra-d_24_hour': 'allegra-d+24_hour',\n",
    "    'allegra-d_24_hour_allergen': 'allegra-d+24_hour',\n",
    "    'allegra_allergen': 'allegra',\n",
    "    'allegra_allergen_childrens': 'allegra+childrens',\n",
    "    'afrin_sinus': 'afrin',\n",
    "    'afrin_12_hour': 'afrin',\n",
    "    'afrin_menthol': 'afrin+menthol',\n",
    "    'afrin_nasal_spray': 'afrin',\n",
    "    'afrin_nodrip_extra_moistu': 'afrin+nodrip+extra_moisture',\n",
    "    'afrin_nodrip_severe_conge': 'afrin+nodrip+severe_congestion',\n",
    "    'afrin_nodrip_sinus': 'afrin+nodrip+sinus',\n",
    "    'afrin_pump_mist': 'afrin',\n",
    "    'agamatrix_presto': 'not_drug',\n",
    "    'agamatrix_ultra-thin_lanc': 'not_drug',\n",
    "    'aimovig': 'aimovig',\n",
    "    'airduo_respiclick_232/14': 'airduo_respiclick',\n",
    "    'airial_compact_mini_nebul': 'not_drug',\n",
    "    'airial_pediatric_nebulize': 'not_drug',\n",
    "    'airs_disposable_nebulizer': 'not_drug',\n",
    "    'alavert_allergen/sinus': 'alavert',\n",
    "    'alaway': 'alaway',\n",
    "    'alaway_childrens_allergen': 'alaway+childrens',\n",
    "    'albuterol': 'albuterol',\n",
    "    'albuterol_sulfate': 'albuterol',\n",
    "    'albuterol_sulfate_er': 'albuterol+er',\n",
    "    'albuterol_sulfate_hfa': 'albuterol+hfa',\n",
    "    'alcohol_pads': 'not_drug',\n",
    "    'alcohol_prep_pads': 'not_drug',\n",
    "    'alcohol_preps': 'not_drug',\n",
    "    'alcohol_swabs': 'not_drug',\n",
    "    'alcortin_a': 'alcortin_a',\n",
    "    'alendronate_sodium': 'alendronate',\n",
    "    'alfuzosin_hcl_er': 'alfuzosin+er',\n",
    "    'alive_womens_50+': 'alive_womens+50',\n",
    "    'alive_womens_energy': 'alive_womens+energy',\n",
    "    'alive_womens_gummy_vitami': 'alive_womens+gummy_vitamin',\n",
    "    'all_day_allergen': 'allergy_relief',\n",
    "    'all_day_allergen-d': 'allergy_relief',\n",
    "    'all_day_allergen_d-12': 'allergy_relief',\n",
    "    'all_day_pain_relief': 'all_day_pain_relief',\n",
    "    'all_day_relief': 'all_day_relief',\n",
    "    'allegra-d_12_hour': 'allergy_relief',\n",
    "    'allegra-d_12_hour_allergen': 'allergy_relief',\n",
    "    'allegra-d_24_hour_allergen': 'allergy_relief',\n",
    "    'allegra_allergen': 'allergy_relief',\n",
    "    'allegra_allergen_childrens': 'allergy_relief',\n",
    "    'allergen_relief': 'allergy_relief',\n",
    "    'allergen_relief/indoor/out': 'allergy_relief',\n",
    "    'allergen_relief/nasal_deco': 'allergy_relief',\n",
    "    'allergen_relief_24hr': 'allergy_relief',\n",
    "    'allergen_relief_child': 'allergy_relief',\n",
    "    'allergen_relief_d-24': 'allergy_relief',\n",
    "    'allergy_relief': 'allergy_relief',\n",
    "    'allergy_relief_24hr': 'allergy_relief',\n",
    "    'allergy_relief_child': 'allergy_relief',\n",
    "    'allergy_relief_d-24': 'allergy_relief',\n",
    "    'allergy_relief/indoor/out': 'allergy_relief',\n",
    "    'allergy_relief/nasal_deco': 'allergy_relief',\n",
    "    'allergy_decongestant': 'allergy_relief',\n",
    "    'alpha-lipoic_acid': 'alpha_lipoic_acid',\n",
    "    'alpha_lipoic_acid': 'alpha_lipoic_acid',\n",
    "    'alpha_lipoic_acid_extra_s': 'alpha_lipoic_acid',\n",
    "    'alprazolam_er': 'alprazolam',\n",
    "    'alprazolam_intensol': 'alprazolam',\n",
    "    'alprazolam_odt': 'alprazolam',\n",
    "    'alprazolam_xr': 'alprazolam',\n",
    "    'alyacen_1/35': 'alyacen',\n",
    "    'alyacen_7/7/7': 'alyacen',\n",
    "    'amantadine_hcl': 'amantadine',\n",
    "    'amantadine_hydrochloride': 'amantadine',\n",
    "    'aspercreme_lidocaine_max': 'aspercreme+lidocaine',\n",
    "    'aspercreme_lidocaine_patc': 'aspercreme+lidocaine',\n",
    "    'aspercreme_max_roll-on_ar': 'aspercreme',\n",
    "    'aspercreme_w+lidocaine': 'aspercreme+lidocaine',\n",
    "    'aspercreme+aloe': 'aspercreme+aloe'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a323f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'a'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"a\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B drug names\n",
    "consolidations_b = {\n",
    "    'b-12': 'vitamin_b12',\n",
    "    'b-12_tr': 'vitamin_b12',\n",
    "    'bacitracin_zinc': 'bacitracin',\n",
    "    'bacitracin+polymyxin_b': 'bacitracin+polymyxin_b',\n",
    "    'baclofen': 'baclofen',\n",
    "    'bactrim': 'sulfamethoxazole+trimethoprim',\n",
    "    'bactrim_ds': 'sulfamethoxazole+trimethoprim',\n",
    "    'bactroban': 'mupirocin',\n",
    "    'bactroban_nasal': 'mupirocin',\n",
    "    'balcoltra': 'balcoltra',\n",
    "    'balsalazide_disodium': 'balsalazide',\n",
    "    'banophen': 'diphenhydramine',\n",
    "    'baqsimi_one_pack': 'glucagon',\n",
    "    'baqsimi_two_pack': 'glucagon',\n",
    "    'basaglar_kwikpen': 'insulin_glargine',\n",
    "    'bayer_microlet_lancets': 'not_drug',\n",
    "    'beclomethasone_dipropiona': 'beclomethasone',\n",
    "    'beconase_aq': 'beclomethasone',\n",
    "    'belbuca': 'buprenorphine',\n",
    "    'belladonna_alkaloids/phen': 'belladonna+phenobarbital',\n",
    "    'belsomra': 'suvorexant',\n",
    "    'benazepril': 'benazepril',\n",
    "    'benazepril+hydrochlorothiazide': 'benazepril+hydrochlorothiazide',\n",
    "    'benicar': 'olmesartan',\n",
    "    'benicar_hct': 'olmesartan+hydrochlorothiazide',\n",
    "    'benlysta': 'belimumab',\n",
    "    'benztropine_mesylate': 'benztropine',\n",
    "    'bepreve': 'bepotastine',\n",
    "    'besivance': 'besifloxacin',\n",
    "    'betamethasone_dipropionat': 'betamethasone',\n",
    "    'betamethasone_valerate': 'betamethasone',\n",
    "    'betaseron': 'interferon_beta-1b',\n",
    "    'bethanechol_chloride': 'bethanechol',\n",
    "    'bevespi_aerosphere': 'glycopyrrolate+formoterol',\n",
    "    'bexsero': 'meningococcal_group_b_vaccine',\n",
    "    'bicalutamide': 'bicalutamide',\n",
    "    'bidil': 'isosorbide_dinitrate+hydralazine',\n",
    "    'biktarvy': 'bictegravir+emtricitabine+tenofovir_alafenamide',\n",
    "    'bimatoprost': 'bimatoprost',\n",
    "    'bisacodyl_ec': 'bisacodyl',\n",
    "    'bisoprolol_fumarate': 'bisoprolol',\n",
    "    'bisoprolol_fumarate/hydro': 'bisoprolol+hydrochlorothiazide',\n",
    "    'blisovi_24_fe': 'ethinyl_estradiol+norethindrone+iron',\n",
    "    'blisovi_fe_1.5/30': 'ethinyl_estradiol+norethindrone+iron',\n",
    "    'blisovi_fe_1/20': 'ethinyl_estradiol+norethindrone+iron',\n",
    "    'boostrix': 'tetanus+diphtheria+pertussis_vaccine',\n",
    "    'bosulif': 'bosutinib',\n",
    "    'botox': 'onabotulinumtoxina',\n",
    "    'bp_wash': 'benzoyl_peroxide',\n",
    "    'braftovi': 'encorafenib',\n",
    "    'breo_ellipta': 'fluticasone+vilanterol',\n",
    "    'brilinta': 'ticagrelor',\n",
    "    'brimonidine_tartrate': 'brimonidine',\n",
    "    'briviact': 'brivaracetam',\n",
    "    'bromfed_dm': 'brompheniramine+dextromethorphan+pseudoephedrine',\n",
    "    'bromocriptine_mesylate': 'bromocriptine',\n",
    "    'bromphen/pseudoephedrine': 'brompheniramine+pseudoephedrine',\n",
    "    'brovana': 'arformoterol',\n",
    "    'budesonide': 'budesonide',\n",
    "    'budesonide_er': 'budesonide',\n",
    "    'budesonide_nasal_spray': 'budesonide',\n",
    "    'budesonide+formoterol_fum': 'budesonide+formoterol',\n",
    "    'bumetanide': 'bumetanide',\n",
    "    'bupap': 'butalbital+acetaminophen',\n",
    "    'bupivacaine': 'bupivacaine',\n",
    "    'buprenorphine': 'buprenorphine',\n",
    "    'buprenorphine_hcl': 'buprenorphine',\n",
    "    'buprenorphine_hcl/naloxon': 'buprenorphine+naloxone',\n",
    "    'bupropion': 'bupropion',\n",
    "    'bupropion_hcl': 'bupropion',\n",
    "    'bupropion_hcl_xl': 'bupropion',\n",
    "    'bupropion_hydrochloride': 'bupropion',\n",
    "    'bupropion_hydrochloride_e': 'bupropion',\n",
    "    'buspirone_hcl': 'buspirone',\n",
    "    'buspirone_hydrochloride': 'buspirone',\n",
    "    'butalbital+acetaminophen': 'butalbital+acetaminophen',\n",
    "    'butorphanol_tartrate': 'butorphanol',\n",
    "    'butrans': 'buprenorphine',\n",
    "    'bydureon': 'exenatide',\n",
    "    'bydureon_bcise': 'exenatide',\n",
    "    'bydureon_pen': 'exenatide',\n",
    "    'byetta': 'exenatide',\n",
    "    'bystolic': 'nebivolol'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2237486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'b'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"b\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C Drug names\n",
    "consolidations_c = {\n",
    "    'cefazolin_sodium+dextrose': 'cefazolin+dextrose',\n",
    "    'clindamycin+sodium_chlori': 'clindamycin+sodium_chloride',\n",
    "    'cvs_b6': 'vitamin_b6',\n",
    "    'cvs_digestive_probiotic': 'probiotic',\n",
    "    'claritin': 'loratadine',\n",
    "    'cvs_allergen': 'cetirizine',\n",
    "    'centrum_men': 'multivitamin+men',\n",
    "    'c-500': 'vitamin_c',\n",
    "    'celexa': 'citalopram',\n",
    "    'clindamycin_hcl': 'clindamycin',\n",
    "    'culturelle_digestive_heal': 'probiotic',\n",
    "    'cvs_spectravite_ultra_men': 'multivitamin+men',\n",
    "    'cvs_allergy_eye_drops': 'allergy_eye_drops',\n",
    "    'cvs_allergy': 'allergy_relief',\n",
    "    'cvs_cold_&hot_maximum_st': 'pain_relief+hot_cold_therapy',\n",
    "    'cvs_motion_sickness_relie': 'motion_sickness_relief',\n",
    "    'caresens_n_blood_glucose': 'not_drug',\n",
    "    'cvs_antiseptic_skin_clean': 'antiseptic_skin_cleanser',\n",
    "    'clocortolone_pivalate_pum': 'clocortolone',\n",
    "    'copper_caps': 'copper',\n",
    "    'classic_prenatal': 'prenatal_vitamin',\n",
    "    'caziant': 'caziant',\n",
    "    'cvs_womens_daily_gummies': 'multivitamin+women',\n",
    "    'cyclosporine_a': 'cyclosporine',\n",
    "    'calcium_500+d3': 'calcium+vitamin_d',\n",
    "    'concept_ob': 'prenatal_vitamin',\n",
    "    'cvs_tension_headache': 'acetaminophen+caffeine',\n",
    "    'cvs_petroleum_jelly': 'petroleum_jelly',\n",
    "    'cepacol_sore_throat_+cou': 'cepacol',\n",
    "    'corvite': 'multivitamin+iron',\n",
    "    'cvs_heartburn_relief': 'heartburn_relief',\n",
    "    'cvs_ibuprofen_ib': 'ibuprofen',\n",
    "    'cytotec': 'misoprostol',\n",
    "    'cvs_triple_antibiotic': 'triple_antibiotic',\n",
    "    'cvs_blood_pressure_cuff': 'not_drug',\n",
    "    'clobetasol_propionate': 'clobetasol',\n",
    "    'cholestyramine_light': 'cholestyramine',\n",
    "    'cimzia': 'certolizumab',\n",
    "    'ciclopirox_nail_lacquer': 'ciclopirox',\n",
    "    'cyproheptadine_hydrochlor': 'cyproheptadine',\n",
    "    'cinacalcet_hydrochloride': 'cinacalcet',\n",
    "    'cetirizine_hydrochloride': 'cetirizine',\n",
    "    'ciprofloxacin_hydrochlori': 'ciprofloxacin',\n",
    "    'cefuroxime_axetil': 'cefuroxime',\n",
    "    'calcium+vitamin_d3': 'calcium+vitamin_d',\n",
    "    'calcitonin_salmon': 'calcitonin',\n",
    "    'calcium_plus_vitamin_d3': 'calcium+vitamin_d',\n",
    "    'clomipramine_hydrochlorid': 'clomipramine',\n",
    "    'calcium_600+_d': 'calcium+vitamin_d',\n",
    "    'coly-mycin_s': 'colistin+neomycin+hydrocortisone',\n",
    "    'cyclobenzaprine_hcl': 'cyclobenzaprine',\n",
    "    'cvs_clotrimazole_3': 'clotrimazole',\n",
    "    'cvs_antifungal_maxiumum_s': 'antifungal',\n",
    "    'castellani_paint_modified': 'castellani_paint',\n",
    "    'culturelle_ultimate_stren': 'probiotic',\n",
    "    'cvs_selenium': 'selenium',\n",
    "    'cvs_athletes_foot_powder': 'antifungal',\n",
    "    'cvs_b-6': 'vitamin_b6',\n",
    "    'cvs_8_hour_pain_relief': 'acetaminophen',\n",
    "    'cvs_anti-dandruff': 'anti_dandruff_shampoo',\n",
    "    'centrum_multigummies_adul': 'multivitamin',\n",
    "    'cvs_spectravite_adult_gum': 'multivitamin',\n",
    "    'cvs_sleep_aid_nighttime+m': 'sleep_aid',\n",
    "    'ciprofloxacin_er': 'ciprofloxacin',\n",
    "    'cvs_nighttime_tussin_dm': 'dextromethorphan+guaifenesin',\n",
    "    'cholecalciferol': 'vitamin_d3',\n",
    "    'c_250': 'vitamin_c',\n",
    "    'clobetasol_propionate': 'clobetasol'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ea5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'c'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"c\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9920947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D drug names\n",
    "\n",
    "consolidations_d = {\n",
    "    'dexmethylphenidate_hcl_er': 'dexmethylphenidate_er',\n",
    "    'dialyvite_800': 'dialyvite',\n",
    "    'dialyvite_800/zinc_15': 'dialyvite+zinc',\n",
    "    'diclofenac_sodium': 'diclofenac',\n",
    "    'diclofenac_epolamine': 'diclofenac',\n",
    "    'diltiazem_hcl_er': 'diltiazem+er',\n",
    "    'diltiazem_hydrochloride_e': 'diltiazem+er',\n",
    "    'dimethyl_fumarate_starter': 'dimethyl_fumarate',\n",
    "    'diphenoxylate/atropine': 'diphenoxylate+atropine',\n",
    "    'disopyramide_phosphate': 'disopyramide',\n",
    "    'divigel': 'estradiol_gel',\n",
    "    'divalproex_sodium_dr': 'divalproex',\n",
    "    'docusate_sodium/senna': 'docusate+senna',\n",
    "    'dobutamine_hydrochloride': 'dobutamine',\n",
    "    'dologesic': 'acetaminophen+caffeine',\n",
    "    'donnatal': 'phenobarbital+belladonna_alkaloids',\n",
    "    'dorzolamide_hydrochloride': 'dorzolamide',\n",
    "    'doxazosin_mesylate': 'doxazosin',\n",
    "    'doxylamine_succinate/pyri': 'doxylamine+pyridoxine',\n",
    "    'dritho-creme_hp': 'anthralin',\n",
    "    'duloxetine_hydrochloride': 'duloxetine',\n",
    "    'dymista': 'azelastine+fluticasone',\n",
    "    'dynabac_5.0': 'dirithromycin'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ff8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'd'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"d\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c45efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E drug names\n",
    "\n",
    "consolidations_e = {\n",
    "    'edarbyclor': 'azilsartan+chlorthalidone',\n",
    "    'eliquis_starter_pack': 'apixaban',\n",
    "    'eq_mucus_relief_dm': 'guaifenesin+dextromethorphan',\n",
    "    'euthyrox': 'levothyroxine',\n",
    "    'epivir': 'lamivudine',\n",
    "    'evotaz': 'atazanavir+cobicistat',\n",
    "    'ethambutol_hydrochloride': 'ethambutol',\n",
    "    'enalapril_maleate': 'enalapril',\n",
    "    'estradiol_valerate': 'estradiol',\n",
    "    'ergocalciferol': 'vitamin_d2',\n",
    "    'estrace': 'estradiol',\n",
    "    'estring': 'estradiol',\n",
    "    'erlotinib_hydrochloride': 'erlotinib',\n",
    "    'ertapenem_sodium': 'ertapenem',\n",
    "    'edex': 'alprostadil',\n",
    "    'epipen': 'epinephrine',\n",
    "    'eylea': 'aflibercept',\n",
    "    'easy_touch_pen_needles_32': 'not_drug',\n",
    "    'easy_touch_fliplock_safet': 'not_drug',\n",
    "    'easy_touch_lancets_30g/pr': 'not_drug',\n",
    "    'easy_touch_safety_lancets': 'not_drug',\n",
    "    'eucerin_skin_calming_dail': 'not_drug',\n",
    "    'eucerin_daily_protection/': 'not_drug'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ceacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'e'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"e\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d069ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F drug names\n",
    "consolidations_f = {\n",
    "    'fioricet': 'butalbital+acetaminophen+caffeine',\n",
    "    'fiorinal+codeine': 'butalbital+acetaminophen+codeine',\n",
    "    'firazyr': 'icatibant',\n",
    "    'firmagon': 'degarelix',\n",
    "    'flagyl': 'metronidazole',\n",
    "    'flagyl_er': 'metronidazole_er',\n",
    "    'flecainide': 'flecainide',\n",
    "    'flomax': 'tamsulosin',\n",
    "    'flonase': 'fluticasone',\n",
    "    'flovent': 'fluticasone',\n",
    "    'focalin': 'dexmethylphenidate',\n",
    "    'forteo': 'teriparatide',\n",
    "    'fosamax': 'alendronate',\n",
    "    'furosemide': 'furosemide'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0311d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'f'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"f\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G drug names\n",
    "\n",
    "consolidations_g = {\n",
    "    'gentamicin_topical': 'gentamicin',\n",
    "    'genvoya': 'elvitegravir+cobicistat+emtricitabine+tenofovir_alafenamide',\n",
    "    'gilenya': 'fingolimod',\n",
    "    'glatiramer_acetate': 'glatiramer',\n",
    "    'glucophage': 'metformin',\n",
    "    'glyxambi': 'empagliflozin+linagliptin',\n",
    "    'gnp_mucus_er': 'guaifenesin',\n",
    "    'gnp_acetylsalicylic_acidirin_low_dose': 'acetylsalicylic_acid',\n",
    "    'gnp_acetylsalicylic_acidirin': 'acetylsalicylic_acid',\n",
    "    'gnp_tussin_dm_cough': 'guaifenesin+dextromethorphan',\n",
    "    'gnp_loratadine': 'loratadine',\n",
    "    'gnp_lancets_thin_26g': 'not_drug',\n",
    "    'glatopa': 'glatiramer',\n",
    "    'glucotrol': 'glipizide',\n",
    "    'glycolax': 'polyethylene_glycol_3350',\n",
    "    'glyxambi': 'empagliflozin+linagliptin',\n",
    "    'gocovri': 'amantadine',\n",
    "    'golytely': 'polyethylene_glycol_3350+electrolytes',\n",
    "    'gvoke_hypopen': 'glucagon',\n",
    "    'guanfacine_hcl': 'guanfacine',\n",
    "    'guanfacine_er': 'guanfacine+er',\n",
    "    'guanfacine_hydrochloride': 'guanfacine'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'g'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"g\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H drug names\n",
    "\n",
    "consolidations_h = {\n",
    "    'harvoni': 'ledipasvir+sofosbuvir',\n",
    "    'humira': 'adalimumab',\n",
    "    'hydrocortisone+acetate+pramoxine': 'hydrocortisone+pramoxine',\n",
    "    'hydrocodone_bitartrate_er': 'hydrocodone+er',\n",
    "    'hydromorphone_hcl_er': 'hydromorphone+er',\n",
    "    'hydroxychloroquine_sulfat': 'hydroxychloroquine',\n",
    "    'humulin_70/30': 'insulin_nph',\n",
    "    'humulin_70/30_kwikpen': 'insulin_nph',\n",
    "    'humulin_n': 'insulin_nph',\n",
    "    'humulin_n_kwikpen': 'insulin_nph',\n",
    "    'humulin_r_u-500': 'insulin_regular',\n",
    "    'halobetasol_propionate': 'halobetasol',\n",
    "    'heparin_lock': 'heparin',\n",
    "    'heparin_lock_flush+sodium_chloride': 'heparin+sodium_chloride',\n",
    "    'humatrope_combo_pack': 'somatropin',\n",
    "    'hurricaine_one': 'benzocaine',\n",
    "    'hydramine': 'diphenhydramine',\n",
    "    'hydroxypropyl_methylcellu': 'hydroxypropyl_methylcellulose',\n",
    "    'h-chlor_12': 'chlorpheniramine',\n",
    "    'hemangeol': 'propranolol'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'h'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"h\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f69c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I drug names\n",
    "\n",
    "consolidations_i = {\n",
    "    'imodium': 'loperamide',\n",
    "    'ibu': 'ibuprofen',\n",
    "    'ibu-200': 'ibuprofen',\n",
    "    'ibu-drops': 'ibuprofen',\n",
    "    'ibu-drops_infants': 'ibuprofen',\n",
    "    'insulin_aspart': 'insulin_aspart',\n",
    "    'insulin_degludec': 'insulin_degludec',\n",
    "    'insulin_detemir': 'insulin_detemir',\n",
    "    'insulin_glargine': 'insulin_glargine',\n",
    "    'insulin_lispro': 'insulin_lispro',\n",
    "    'insulin_regular': 'insulin_regular',\n",
    "    'ibrance': 'palbociclib',\n",
    "    'iclusig': 'ponatinib',\n",
    "    'idhifa': 'enasidenib',\n",
    "    'ilumya': 'tildrakizumab',\n",
    "    'imbruvica': 'ibrutinib',\n",
    "    'imdur': 'isosorbide_mononitrate',\n",
    "    'imfinzi': 'durvalumab',\n",
    "    'imitrex': 'sumatriptan',\n",
    "    'impoyz': 'clobetasol',\n",
    "    'imuran': 'azathioprine',\n",
    "    'inbrija': 'levodopa',\n",
    "    'incruse_ellipta': 'umeclidinium',\n",
    "    'inderal': 'propranolol',\n",
    "    'indocin': 'indomethacin',\n",
    "    'inflectra': 'infliximab',\n",
    "    'ingrezza': 'valbenazine',\n",
    "    'injectafer': 'ferric_carboxymaltose',\n",
    "    'inlyta': 'axitinib',\n",
    "    'inrebic': 'fedratinib',\n",
    "    'intuniv': 'guanfacine',\n",
    "    'invega': 'paliperidone',\n",
    "    'invokana': 'canagliflozin'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54225b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'i'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"i\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# J drug names\n",
    "\n",
    "consolidations_j = {\n",
    "    'januvia': 'sitagliptin',\n",
    "    'jornay_pm': 'methylphenidate',\n",
    "    'jublia': 'efinaconazole',\n",
    "    'junel_fe_24': 'ethinyl_estradiol+norethindrone+iron',\n",
    "    'jardiance': 'empagliflozin',\n",
    "    'jantoven': 'warfarin',\n",
    "    'janumet': 'sitagliptin+metformin',\n",
    "    'jakafi': 'ruxolitinib',\n",
    "    'jadenu': 'deferasirox',\n",
    "    'jentadueto': 'linagliptin+metformin',\n",
    "    'jevtana': 'cabazitaxel',\n",
    "    'jencycla': 'norethindrone',\n",
    "    'juluca': 'dolutegravir+rilpivirine',\n",
    "    'junel_fe_1/20': 'ethinyl_estradiol+norethindrone+iron',\n",
    "    'junel_fe_1.5/30': 'ethinyl_estradiol+norethindrone+iron',\n",
    "    'junel_1/20': 'ethinyl_estradiol+norethindrone',\n",
    "    'junel_1.5/30': 'ethinyl_estradiol+norethindrone',\n",
    "    'jinteli': 'ethinyl_estradiol+norethindrone'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838cccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee074ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'j'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"j\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K drug names\n",
    "\n",
    "consolidations_k = {\n",
    "    'kaletra': 'lopinavir+ritonavir',\n",
    "    'kcentra': 'prothrombin_complex_concentrate',\n",
    "    'keflex': 'cephalexin',\n",
    "    'keppra': 'levetiracetam',\n",
    "    'keytruda': 'pembrolizumab',\n",
    "    'kineret': 'anakinra',\n",
    "    'kisqali': 'ribociclib',\n",
    "    'klonopin': 'clonazepam',\n",
    "    'klor-con': 'potassium_chloride',\n",
    "    'kombiglyze_xr': 'metformin+saxagliptin',\n",
    "    'kuvan': 'sapropterin',\n",
    "    'kyleena': 'levonorgestrel'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4636b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed6b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'k'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"k\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L drug names\n",
    "consolidations_l = {\n",
    "    'lovaza': 'omega-3-acid_ethyl_esters',\n",
    "    'lucemyra': 'lofexidine',\n",
    "    'lyrica': 'pregabalin',\n",
    "    'levalbuterol_tartrate_hfa': 'levalbuterol',\n",
    "    'lidocaine_hydrochloride': 'lidocaine',\n",
    "    'lidocaine_5%': 'lidocaine',\n",
    "    'livalo': 'pitavastatin',\n",
    "    'lmx_5': 'lidocaine',\n",
    "    'loestrin_fe_1.5/30': 'ethinyl_estradiol+norethindrone+iron',\n",
    "    'loestrin_1/20-21': 'ethinyl_estradiol+norethindrone',\n",
    "    'loteprednol_etabonate': 'loteprednol',\n",
    "    'loxasperse': 'not_drug',\n",
    "    'lysodren': 'mitotane'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14235a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'l'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"l\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ff629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M drug names\n",
    "\n",
    "consolidations_m = {\n",
    "    'metformin_hydrochloride': 'metformin',\n",
    "    'metformin_hydrochloride_e': 'metformin_er',\n",
    "    'metoprolol_tartrate': 'metoprolol',\n",
    "    'metformin_hcl': 'metformin',\n",
    "    'methylprednisolone_dose_p': 'methylprednisolone',\n",
    "    'memantine_hydrochloride': 'memantine',\n",
    "    'metoclopramide_hcl': 'metoclopramide',\n",
    "    'medroxyprogesterone_aceta': 'medroxyprogesterone',\n",
    "    'metoprolol_succinate_er': 'metoprolol_er',\n",
    "    'methylphenidate_hydrochlo': 'methylphenidate',\n",
    "    'metformin_hcl_er': 'metformin_er',\n",
    "    'montelukast_sodium': 'montelukast',\n",
    "    'methotrexate': 'methotrexate',\n",
    "    'metoprolol_tartrate': 'metoprolol',\n",
    "    'methadone_hcl': 'methadone',\n",
    "    'minocycline_hcl': 'minocycline',\n",
    "    'metoprolol_succinate': 'metoprolol',\n",
    "    'methenamine_hippurate': 'methenamine',\n",
    "    'methylphenidate_hcl_er': 'methylphenidate_er',\n",
    "    'metronidazole_vaginal': 'metronidazole',\n",
    "    'metoprolol_tartrate/hydro': 'metoprolol+hydrochlorothiazide',\n",
    "    'midodrine_hcl': 'midodrine',\n",
    "    'metoclopramide_hydrochlo': 'metoclopramide',\n",
    "    'meclizine_hcl': 'meclizine',\n",
    "    'megestrol_acetate': 'megestrol',\n",
    "    'metformin/sitagliptin': 'metformin+sitagliptin',\n",
    "    'mycophenolate_mofetil': 'mycophenolate',\n",
    "    'methadone_hydrochloride': 'methadone',\n",
    "    'miconazole_nitrate': 'miconazole',\n",
    "    'metronidazole_er': 'metronidazole+er',\n",
    "    'methylphenidate_er': 'methylphenidate_er',\n",
    "    'morphine_sulfate_er': 'morphine+er',\n",
    "    'moxifloxacin_hcl': 'moxifloxacin',\n",
    "    'metoprolol_er_succinate': 'metoprolol_er',\n",
    "    'miralax': 'polyethylene_glycol_3350',\n",
    "    'metamucil': 'psyllium',\n",
    "    'mometasone_furoate': 'mometasone',\n",
    "    'multivitamin/minerals': 'multivitamin+minerals'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84432506",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab937901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'm'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"m\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de477bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N drug names\n",
    "\n",
    "consolidations_n = {\n",
    "    'namenda': 'memantine',\n",
    "    'naprosyn': 'naproxen',\n",
    "    'narcan': 'naloxone',\n",
    "    'nasacort': 'triamcinolone',\n",
    "    'nasonex': 'mometasone',\n",
    "    'neosporin': 'bacitracin+neomycin+polymyxin_b',\n",
    "    'neurontin': 'gabapentin',\n",
    "    'nexium': 'esomeprazole',\n",
    "    'nexium_24hr': 'esomeprazole',\n",
    "    'nizoral_a-d': 'nizoral',\n",
    "    'norco': 'hydrocodone+acetaminophen',\n",
    "    'norvasc': 'amlodipine',\n",
    "    'nortriptyline_hydrochlori': 'nortriptyline',\n",
    "    'nortriptyline_hcl': 'nortriptyline',\n",
    "    'novolin_n': 'insulin_nph',\n",
    "    'novolog': 'insulin_aspart',\n",
    "    'np_thyroid': 'thyroid',\n",
    "    'nystatin_topical': 'nystatin',\n",
    "    'novolin_70/30': 'insulin_nph',\n",
    "    'novolin_70/30_flexpen': 'insulin_nph',\n",
    "    'novolin_70/30_flexpen_rel': 'insulin_nph',\n",
    "    'novolin_70/30_penfill': 'insulin_nph',\n",
    "    'novolin_70/30_relion': 'insulin_nph',\n",
    "    'novolin_n': 'insulin_nph',\n",
    "    'novolin_n_flexpen': 'insulin_nph',\n",
    "    'novolin_n_flexpen_relion': 'insulin_nph',\n",
    "    'novolin_n_relion': 'insulin_nph',\n",
    "    'novolin_r': 'insulin_regular',\n",
    "    'novolin_r_flexpen_relion': 'insulin_regular',\n",
    "    'novolin_r_relion': 'insulin_regular',\n",
    "    'novolog': 'insulin_aspart',\n",
    "    'novolog_flexpen': 'insulin_aspart',\n",
    "    'novolog_mix_70/30': 'insulin_aspart+protamine',\n",
    "    'novolog_mix_70/30_prefill': 'insulin_aspart+protamine',\n",
    "    'novolog_penfill': 'insulin_aspart',\n",
    "    'np_thyroid_120': 'np_thyroid',\n",
    "    'np_thyroid_15': 'np_thyroid',\n",
    "    'np_thyroid_30': 'np_thyroid',\n",
    "    'np_thyroid_60': 'np_thyroid',\n",
    "    'np_thyroid_90': 'np_thyroid',\n",
    "    'nystatin_foreign': 'nystatin',\n",
    "    'nystatin+triamcinolone_ac': 'nystatin+triamcinolone'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e818309",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'n'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"n\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd11586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O drug names\n",
    "\n",
    "consolidations_o = {\n",
    "    'oxycodone_hydrochloride': 'oxycodone',\n",
    "    'oxycodone+acetaminophen': 'oxycodone+acetaminophen',\n",
    "    'ondansetron_hydrochloride': 'ondansetron',\n",
    "    'ondansetron_hcl': 'ondansetron',\n",
    "    'ondansetron_hcl_dihydrate': 'ondansetron',\n",
    "    'ondansetron_odt': 'ondansetron+odt',\n",
    "    'oxybutynin_chloride': 'oxybutynin',\n",
    "    'oxybutynin_chloride_er': 'oxybutynin+er',\n",
    "    'olmesartan_medoxomil': 'olmesartan',\n",
    "    'omega-3-acid_ethyl_esters': 'omega-3-acid_ethyl_esters',\n",
    "    'oseltamivir_phosphate': 'oseltamivir',\n",
    "    'oxymorphone_hydrochloride': 'oxymorphone',\n",
    "    'optivar': 'azelastine',\n",
    "    'opsumit': 'macitentan',\n",
    "    'ocaliva': 'obeticholic_acid',\n",
    "    'octagam': 'immune_globulin_intravenous',\n",
    "    'ocuflox': 'ofloxacin_ophthalmic',\n",
    "    'ofev': 'nintedanib',\n",
    "    'ogivri': 'trastuzumab',\n",
    "    'olumiant': 'baricitinib',\n",
    "    'omnaris': 'ciclesonide_nasal',\n",
    "    'onfi': 'clobazam',\n",
    "    'onglyza': 'saxagliptin',\n",
    "    'onpattro': 'patisiran',\n",
    "    'opana': 'oxymorphone',\n",
    "    'opdivo': 'nivolumab',\n",
    "    'opsumit': 'macitentan',\n",
    "    'oracea': 'doxycycline',\n",
    "    'oralair': 'grass_pollen_allergen_extract',\n",
    "    'oravig': 'miconazole',\n",
    "    'orencia': 'abatacept',\n",
    "    'orfadin': 'nitisinone',\n",
    "    'orkambi': 'lumacaftor+ivacaftor',\n",
    "    'ortho_evra': 'ethinyl_estradiol+norelgestromin',\n",
    "    'ortho_tri-cyclen': 'ethinyl_estradiol+norgestimate',\n",
    "    'oseni': 'alogliptin+pioglitazone',\n",
    "    'otezla': 'apremilast',\n",
    "    'oxaydo': 'oxycodone',\n",
    "    'oxtellar_xr': 'oxcarbazepine',\n",
    "    'ozempic': 'semaglutide',\n",
    "    'olanzapine_odt': 'olanzapine+odt',\n",
    "    'olmesartan_medoxomil': 'olmesartan',\n",
    "    'olmesartan_medoxomil+amlo': 'olmesartan+amlodipine',\n",
    "    'olmesartan_medoxomil+hydr': 'olmesartan+hydrochlorothiazide',\n",
    "    'omega-3-6-9': 'omega-3+6+9',\n",
    "    'omega-3-acid_ethyl_esters': 'omega-3',\n",
    "    'omega-3_2100': 'omega-3',\n",
    "    'omega-3_cf': 'omega-3',\n",
    "    'omega-3_epa_fish_oil': 'omega-3',\n",
    "    'omega-3_fish_oil': 'omega-3',\n",
    "    'omega-3_fish_oil_maximum': 'omega-3',\n",
    "    'omega-3_fish_oil_no_burp': 'omega-3',\n",
    "    'omega-3_krill_oil': 'omega-3+krill_oil',\n",
    "    'omega-3_rx_complete': 'omega-3',\n",
    "    'omega-3+d-3_wellness_pack': 'omega-3+vitamin_d3',\n",
    "    'omega_3': 'omega-3',\n",
    "    'omega_3-6-9_complex': 'omega-3+6+9',\n",
    "    'omega_iii_epa+docosahexaenoic_acid': 'omega-3'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4604c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19fdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'o'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"o\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ac08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P drug names\n",
    "\n",
    "consolidations_p = {\n",
    "    'pantoprazole_sodium': 'pantoprazole',\n",
    "    'paroxetine_hcl': 'paroxetine',\n",
    "    'paroxetine_hcl_er': 'paroxetine+er',\n",
    "    'paroxetine_hydrochloride': 'paroxetine',\n",
    "    'penicillin_v_potassium': 'penicillin',\n",
    "    'penicillin_g_potassium': 'penicillin',\n",
    "    'penicillin_g_sodium': 'penicillin',\n",
    "    'phenytoin_sodium_extended': 'phenytoin',\n",
    "    'pioglitazone_hcl': 'pioglitazone',\n",
    "    'potassium_chloride_er': 'potassium_chloride+er',\n",
    "    'pravastatin_sodium': 'pravastatin',\n",
    "    'prednisolone_acetate': 'prednisolone',\n",
    "    'prednisone_intensol': 'prednisone',\n",
    "    'promethazine_hcl': 'promethazine',\n",
    "    'propranolol_hcl': 'propranolol',\n",
    "    'peg3350': 'polyethylene_glycol_3350',\n",
    "    'peg_3350': 'polyethylene_glycol_3350',\n",
    "    'pneumovax_23': 'pneumococcal_vaccine',\n",
    "    'pradaxa': 'dabigatran',\n",
    "    'proair_hfa': 'albuterol',\n",
    "    'pyridium': 'phenazopyridine',\n",
    "    'plavix': 'clopidogrel',\n",
    "    'protonix': 'pantoprazole',\n",
    "    'prozac': 'fluoxetine',\n",
    "    'premarin': 'conjugated_estrogens',\n",
    "    'prilosec': 'omeprazole',\n",
    "    'prevacid': 'lansoprazole',\n",
    "    'plaquenil': 'hydroxychloroquine',\n",
    "    'paxil': 'paroxetine',\n",
    "    'proventil_hfa': 'albuterol',\n",
    "    'provera': 'medroxyprogesterone',\n",
    "    'prograf': 'tacrolimus',\n",
    "    'percocet': 'oxycodone+acetaminophen',\n",
    "    'prempro': 'conjugated_estrogens+medroxyprogesterone',\n",
    "    'procardia_xl': 'nifedipine',\n",
    "    'provigil': 'modafinil',\n",
    "    'prilosec_otc': 'omeprazole',\n",
    "    'phenazopyridine_hcl': 'phenazopyridine',\n",
    "    'phenazopyridine_hydrochlo': 'phenazopyridine',\n",
    "    'phentermine_hcl': 'phentermine',\n",
    "    'phentermine_hydrochloride': 'phentermine',\n",
    "    'phentolamine_mesylate': 'phentolamine',\n",
    "    'phenylephrine_hydrochlori': 'phenylephrine',\n",
    "    'pilocarpine_hcl': 'pilocarpine',\n",
    "    'pilocarpine_hydrochloride': 'pilocarpine',\n",
    "    'pioglitazone_hcl': 'pioglitazone',\n",
    "    'pioglitazone_hydrochlorid': 'pioglitazone',\n",
    "    'pioglitazone_hcl+glimepir': 'pioglitazone+glimepiride',\n",
    "    'pioglitazone_hcl+metformi': 'pioglitazone+metformin',\n",
    "    'piperacillin_sodium+tazob': 'piperacillin+tazobactam',\n",
    "    'piperacillin+tazobactam': 'piperacillin+tazobactam',\n",
    "    'prazosin_hcl': 'prazosin',\n",
    "    'prazosin_hydrochloride': 'prazosin',\n",
    "    'peg-3350+electrolytes': 'polyethylene_glycol_3350+electrolytes',\n",
    "    'peg-3350+electrolytes+asc': 'polyethylene_glycol_3350+electrolytes',\n",
    "    'peg-3350+nacl+na_bicarbon': 'polyethylene_glycol_3350+electrolytes',\n",
    "    'peg-3350+sodium_sulf+nacl': 'polyethylene_glycol_3350+electrolytes',\n",
    "    'peg-3350+sodium_chloride+na_bicarbon': 'polyethylene_glycol_3350+electrolytes',\n",
    "    'peg-3350+sodium_sulf+sodium_chloride': 'polyethylene_glycol_3350+electrolytes',\n",
    "    'peg_3350': 'polyethylene_glycol_3350',\n",
    "    'peg_3350+electrolytes': 'polyethylene_glycol_3350+electrolytes',\n",
    "    'peg3350': 'polyethylene_glycol_3350',\n",
    "    'piqray_200mg_daily_dose': 'piqray',\n",
    "    'piqray_250mg_daily_dose': 'piqray',\n",
    "    'piqray_300mg_daily_dose': 'piqray',\n",
    "    'pirmella_1/35': 'pirmella',\n",
    "    'pirmella_7/7/7': 'pirmella',\n",
    "    'pneumovax_23': 'pneumococcal_vaccine',\n",
    "    'pneumovax_23/1_dose': 'pneumococcal_vaccine',\n",
    "    'pneumovax_23/5_dose': 'pneumococcal_vaccine',\n",
    "    'potassium_chloride+dextro': 'potassium_chloride+dextrose',\n",
    "    'potassium_chloride+sodium': 'potassium_chloride+sodium_chloride',\n",
    "    'potassium_chloride_0.15%+d5w+sodium_chloride_0.45%': 'potassium_chloride+dextrose+sodium_chloride',\n",
    "    'potassium_chloride_0.15%+d5w+sodium_chloride_0.9%': 'potassium_chloride+dextrose+sodium_chloride',\n",
    "    'potassium_chloride_0.3%+d5w+sodium_chloride_0.45%': 'potassium_chloride+dextrose+sodium_chloride',\n",
    "    'potassium_chloride_cr': 'potassium_chloride+cr',\n",
    "    'potassium_chloride_er': 'potassium_chloride+er',\n",
    "    'potassium_chloride_sr': 'potassium_chloride+sr',\n",
    "    'prednisolone_acetate': 'prednisolone',\n",
    "    'prednisolone_acetate_p-f': 'prednisolone',\n",
    "    'prednisolone_sodium_phosp': 'prednisolone',\n",
    "    'prednisolonee_sodium_phosp': 'prednisolone',\n",
    "    'prednisolonee': 'prednisolone',\n",
    "    'prednisone': 'prednisone',\n",
    "    'prednisone_intensol': 'prednisone'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9632f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'p'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"p\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q drug names\n",
    "\n",
    "consolidations_q = {\n",
    "    'quetiapine_fumarate': 'quetiapine',\n",
    "    'quetiapine_fumarate_er': 'quetiapine+er',\n",
    "    'quinapril_hydrochloride': 'quinapril',\n",
    "    'quinapril_hcl': 'quinapril',\n",
    "    'qnasl': 'beclomethasone',\n",
    "    'quartette': 'levonorgestrel+ethinyl_estradiol',\n",
    "    'quasense': 'levonorgestrel+ethinyl_estradiol',\n",
    "    'quillichew_er': 'methylphenidate+er',\n",
    "    'quillivant_xr': 'methylphenidate+er',\n",
    "    'quinidine_sulfate': 'quinidine',\n",
    "    'quinine_sulfate': 'quinine',\n",
    "    'qvar': 'beclomethasone',\n",
    "    'qvar_redihaler': 'beclomethasone'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c2362",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e318d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'q'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"q\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R drug names\n",
    "\n",
    "consolidations_r = {\n",
    "    'raloxifene_hydrochloride': 'raloxifene',\n",
    "    'ranitidine_hydrochloride': 'ranitidine',\n",
    "    'reclast': 'zoledronic_acid',\n",
    "    'regenecare_ha': 'lidocaine',\n",
    "    'relion_ultra_thin_lancets': 'not_drug',\n",
    "    'repatha': 'evolocumab',\n",
    "    'repatha_sureclick': 'evolocumab',\n",
    "    'restasis': 'cyclosporine_ophthalmic',\n",
    "    'restasis_multidose': 'cyclosporine_ophthalmic',\n",
    "    'revlimid': 'lenalidomide',\n",
    "    'rexulti': 'brexpiprazole',\n",
    "    'reyataz': 'atazanavir',\n",
    "    'ribasphere': 'ribavirin',\n",
    "    'risedronate_sodium': 'risedronate',\n",
    "    'risedronate_sodium_dr': 'risedronate',\n",
    "    'rivastigmine_transdermal': 'rivastigmine',\n",
    "    'rosuvastatin_calcium': 'rosuvastatin',\n",
    "    'rozerem': 'ramelteon',\n",
    "    'rydapt': 'midostaurin'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0589a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'r'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"r\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop sort priority column to use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfeb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S drug names\n",
    "\n",
    "consolidations_s = {\n",
    "    'sertraline_hcl': 'sertraline',\n",
    "    'sumatriptan_succinate': 'sumatriptan',\n",
    "    'symbicort': 'budesonide+formoterol',\n",
    "    'synthroid': 'levothyroxine',\n",
    "    'senna': 'sennosides',\n",
    "    'senna_plus': 'sennosides+docusate',\n",
    "    'senna_s': 'sennosides+docusate',\n",
    "    'sevelamer_carbonate': 'sevelamer',\n",
    "    'sevelamer_hcl': 'sevelamer',\n",
    "    'sildenafil_citrate': 'sildenafil',\n",
    "    'sitagliptin_phosphate': 'sitagliptin',\n",
    "    'solifenacin_succinate': 'solifenacin',\n",
    "    'sotalol_hcl': 'sotalol',\n",
    "    'spiriva': 'tiotropium',\n",
    "    'sumatriptan_succinate': 'sumatriptan',\n",
    "    'symbicort': 'budesonide+formoterol'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 's'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"s\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f01bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T drug names\n",
    "\n",
    "consolidations_t = {\n",
    "    'tamsulosin_hydrochloride': 'tamsulosin',\n",
    "    'testosterone_cypionate': 'testosterone',\n",
    "    'tiotropium_bromide': 'tiotropium',\n",
    "    'topiramate_er': 'topiramate+er',\n",
    "    'tramadol_hcl': 'tramadol',\n",
    "    'trazodone_hydrochloride': 'trazodone',\n",
    "    'triamcinolone_acetonide': 'triamcinolone',\n",
    "    'toujeo_solostar': 'insulin_glargine',\n",
    "    'travatan_z': 'travoprost',\n",
    "    'tresiba': 'insulin_degludec',\n",
    "    'trulicity': 'dulaglutide',\n",
    "    'tysabri': 'natalizumab'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0538f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 't'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"t\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e942dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U drug names\n",
    "\n",
    "consolidations_u = {\n",
    "    'unifine_safecontrol_pen_n': 'not_drug',\n",
    "    'ulticare_short_pen_needle': 'not_drug',\n",
    "    'ultra-care_lancets_30g': 'not_drug',\n",
    "    'unilet_lancets_micro-thin': 'not_drug',\n",
    "    'unistik_czt_normal': 'not_drug',\n",
    "    'ultra-care_alcohol_prep_p': 'not_drug',\n",
    "    'ultilet_lancets': 'not_drug',\n",
    "    'unisol_4': 'unisol'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae621b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'u'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"u\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b556ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V drug names\n",
    "\n",
    "consolidations_v = {\n",
    "    'valtrex': 'valacyclovir',\n",
    "    'vancomycin_hcl': 'vancomycin',\n",
    "    'vascepa': 'icosapent_ethyl',\n",
    "    'venlafaxine_hcl': 'venlafaxine',\n",
    "    'venlafaxine_hcl_er': 'venlafaxine+er',\n",
    "    'ventolin_hfa': 'albuterol',\n",
    "    'verapamil_hcl': 'verapamil',\n",
    "    'verapamil_hcl_er': 'verapamil+er',\n",
    "    'vesicare': 'solifenacin',\n",
    "    'viagra': 'sildenafil',\n",
    "    'victoza': 'liraglutide',\n",
    "    'viibryd': 'vilazodone',\n",
    "    'vitamin_b-12': 'vitamin_b12',\n",
    "    'vitamin_b12': 'vitamin_b12',\n",
    "    'vitamin_d': 'vitamin_d',\n",
    "    'vitamin_d3': 'vitamin_d3',\n",
    "    'vitekta': 'elvitegravir',\n",
    "    'vistaril': 'hydroxyzine',\n",
    "    'vit_d': 'vitamin_d',\n",
    "    'voltaren': 'diclofenac',\n",
    "    'voriconazole': 'voriconazole',\n",
    "    'vraylar': 'cariprazine',\n",
    "    'vytorin': 'ezetimibe+simvastatin'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7835b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'v'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"v\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6944ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W drug names\n",
    "\n",
    "consolidations_w = {\n",
    "    'warfarin_sodium': 'warfarin',\n",
    "    'wellbutrin_sr': 'bupropion',\n",
    "    'westhroid': 'thyroid',\n",
    "    'wymzya_fe': 'ethinyl_estradiol+norethindrone+iron',\n",
    "    'wal-fex_allergen': 'fexofenadine',\n",
    "    'wal-phed': 'pseudoephedrine',\n",
    "    'wal-itin_d_24_hour': 'loratadine+pseudoephedrine',\n",
    "    'wal-tussin_cough': 'guaifenesin',\n",
    "    'wal-tussin_cough_&_chest': 'guaifenesin',\n",
    "    'wal-zan_75': 'ranitidine',\n",
    "    'walgreens_glucose': 'glucose',\n",
    "    'walgreens_ultra_thin_lanc': 'not_drug',\n",
    "    'wp_thyroid': 'thyroid'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d97f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ebfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'w'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"w\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da391bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X drug names\n",
    "\n",
    "consolidations_x = {\n",
    "    'xigduo_xr': 'dapagliflozin+metformin',\n",
    "    'xolair': 'omalizumab',\n",
    "    'xarelto': 'rivaroxaban',\n",
    "    'xanax': 'alprazolam',\n",
    "    'xeljanz': 'tofacitinib',\n",
    "    'xulane': 'ethinyl_estradiol+norelgestromin',\n",
    "    'xarelto_starter_pack': 'rivaroxaban',\n",
    "    'xofluza': 'baloxavir_marboxil',\n",
    "    'xyzal': 'levocetirizine',\n",
    "    'xtampza_er': 'oxycodone',\n",
    "    'xeomin': 'incobotulinumtoxina',\n",
    "    'xifaxan': 'rifaximin',\n",
    "    'xylocaine': 'lidocaine',\n",
    "    'xalatan': 'latanoprost',\n",
    "    'xgeva': 'denosumab',\n",
    "    'xofluza': 'baloxavir_marboxil',\n",
    "    'xarelto_dose_pack': 'rivaroxaban',\n",
    "    'xcopri': 'cenobamate',\n",
    "    'xeljanz_xr': 'tofacitinib',\n",
    "    'xyrem': 'sodium_oxybate',\n",
    "    'xylocaine': 'lidocaine',\n",
    "    'xylocaine-mpf': 'lidocaine',\n",
    "    'xylocaine-mpf+epinephrine': 'lidocaine+epinephrine',\n",
    "    'xylocaine_jelly': 'lidocaine_gel',\n",
    "    'xylocaine+epinephrine': 'lidocaine+epinephrine'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b9dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'x'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"x\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y drug names\n",
    "\n",
    "consolidations_y = {\n",
    "    'yaz': 'ethinyl_estradiol+drospirenone',\n",
    "    'yasmin': 'ethinyl_estradiol+drospirenone',\n",
    "    'yuvafem': 'estradiol',\n",
    "    'yosprala': 'aspirin+omeprazole',\n",
    "    'yondelis': 'trabectedin',\n",
    "    'yohimbine': 'yohimbine',\n",
    "    'yupelri': 'revefenacin'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302977be",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'y'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"y\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de295f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z drug names\n",
    "\n",
    "consolidations_z = {\n",
    "    'zenpep': 'pancrelipase',\n",
    "    'zithromax': 'azithromycin',\n",
    "    'zolpidem_tartrate': 'zolpidem',\n",
    "    'zyprexa': 'olanzapine',\n",
    "    'zylet': 'lotepraxol+tobramycin',\n",
    "    'zerbaxa': 'ceftolozane+tazobactam',\n",
    "    'zyloprim': 'allopurinol',\n",
    "    'zirgan': 'ganciclovir_ophthalmic',\n",
    "    'ziprasidone_hcl': 'ziprasidone',\n",
    "    'zolpimist': 'zolpidem',\n",
    "    'zostrix': 'capsaicin',\n",
    "    'zofran': 'ondansetron',\n",
    "    'zyrtec': 'cetirizine',\n",
    "    'zantac': 'ranitidine',\n",
    "    'zetia': 'ezetimibe',\n",
    "    'zovirax': 'acyclovir',\n",
    "    'zocor': 'simvastatin',\n",
    "    'zoloft': 'sertraline'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeecd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Add a custom sort column that prioritizes names starting with 'z'\n",
    "sorted_unique_levels = clean_df.withColumn(\n",
    "    \"sort_priority\",\n",
    "    when(col(\"standardized_drug_name\").startswith(\"z\"), 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Sort by the custom sort priority, and then alphabetically by 'standardized_drug_name'\n",
    "sorted_unique_levels = sorted_unique_levels.orderBy(\n",
    "    col(\"sort_priority\"), \n",
    "    col(\"standardized_drug_name\").asc()\n",
    ")\n",
    "\n",
    "# Drop priority sort column so we can use for new cases\n",
    "sorted_unique_levels = sorted_unique_levels.drop(\"sort_priority\")\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_unique_levels.show(n=20)  # Adjust 'n' to display more or fewer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac654535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not drugs\n",
    "\n",
    "consolidations_not_drugs = {\n",
    "    '3ml_luer-lok_syringe': 'not_drug',\n",
    "    'bd_insulin_syringe': 'not_drug',\n",
    "    'truedraw_lancing_device': 'not_drug',\n",
    "    'kroger_lancing_device': 'not_drug',\n",
    "    'alcohol_prep_pads': 'not_drug',\n",
    "    'lancets': 'not_drug',\n",
    "    'catheters': 'not_drug',\n",
    "    'cvs_moisturizing_cream': 'not_drug',\n",
    "    'hrt_cream_base': 'not_drug',\n",
    "    'systane_gel': 'not_drug',\n",
    "    'arnica_gel': 'not_drug',\n",
    "    'cvs_moisturizing_lotion': 'not_drug',\n",
    "    'salicylic_acid_lotion': 'not_drug',\n",
    "    'silverseal_hydrogel_dress': 'not_drug',\n",
    "    'carrasyn_hydrogel_wound_d': 'not_drug',\n",
    "    'ra_saline_nasal_spray': 'not_drug',\n",
    "    'little_noses_saline': 'not_drug',\n",
    "    'refresh_liquigel': 'not_drug',\n",
    "    'eye_irrigating_solutions': 'not_drug',\n",
    "    'control_solutions_for_glucose_meters': 'not_drug',\n",
    "    'vaginal_cream_applicators': 'not_drug',\n",
    "    'silica_gel_packets': 'not_drug',\n",
    "    'alcohol_prep_pads': 'not_drug',\n",
    "    'prodigy_twist_top_lancets': 'not_drug',\n",
    "    'alcohol_swabs': 'not_drug',\n",
    "    'sm_alcohol_prep_pads': 'not_drug',\n",
    "    'sterile_water_for_irrigat': 'not_drug',\n",
    "    'dexcom_g5_mobile_transmit': 'not_drug',\n",
    "    'easy_touch_32gx6mm': 'not_drug',\n",
    "    'ulticare_short_pen_needle': 'not_drug',\n",
    "    'global_inject_ease_insuli': 'not_drug',\n",
    "    'e-z-disk': 'not_drug',\n",
    "    'accu-chek_guide': 'not_drug',\n",
    "    'true_metrix': 'not_drug',\n",
    "    't:flex': 'not_drug',\n",
    "    't:slim': 'not_drug',\n",
    "    'prodigy_pocket_no_match_gluc': 'not_drug',\n",
    "    'compact_space_chamber/ant': 'not_drug',\n",
    "    'onetouch_suresoft_lancing': 'not_drug',\n",
    "    'relion_ultra_thin_lancets': 'not_drug',\n",
    "    'bd_pen_needle/mini/ultra-': 'not_drug',\n",
    "    'accu-chek_fastclix_lancet': 'not_drug',\n",
    "    'adjustable_lancing_device': 'not_drug',\n",
    "    'bd_1ml_tuberculin_syringe': 'not_drug',\n",
    "    'novofine_autocover_pen_ne': 'not_drug',\n",
    "    'unifine_pentips_plus_31gx': 'not_drug',\n",
    "    'optichamber_diamond': 'not_drug',\n",
    "    'bayer_microlet_lancets': 'not_drug',\n",
    "    'onetouch_delica_lancets_e': 'not_drug',\n",
    "    'trueplus_lancets_30g_ultr': 'not_drug',\n",
    "    'freestyle_libre/sensor/fl': 'not_drug',\n",
    "    'relion_pen_needles/31g_x': 'not_drug',\n",
    "    'bd_pen_needle/nano_2nd_ge': 'not_drug',\n",
    "    'ulticare_insulin_syringe/': 'not_drug',\n",
    "    'accu-chek_aviva': 'not_drug'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = replace_values_with_mapping(clean_df, 'standardized_drug_name', consolidations_not_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8984ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Group by drug name and get counts\n",
    "unique_levels_clean = clean_df.groupBy(\"standardized_drug_name\").count()\n",
    "\n",
    "# Order by count in descending order\n",
    "unique_levels_clean = unique_levels_clean.orderBy(col(\"count\").desc())\n",
    "\n",
    "# Show the sorted results\n",
    "unique_levels_clean.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61984ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Drop rows where standardized_drug_name is 'not_drug' or 'unknown'\n",
    "clean_df = clean_df.filter(~col('standardized_drug_name').isin('not_drug', 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ea321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Group by drug name and get counts\n",
    "levels_unique = clean_df.groupBy(\"standardized_drug_name\").count()\n",
    "\n",
    "# Order by count in descending order\n",
    "levels_unique = levels_unique.orderBy(col(\"count\").desc())\n",
    "\n",
    "# Show the sorted results\n",
    "levels_unique.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37300890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the number of partitions to optimize data collection\n",
    "levels_unique = levels_unique.coalesce(1)  # Reduce to 1 partition\n",
    "\n",
    "# Collect the results as a pandas DataFrame\n",
    "unique_drug_names = levels_unique.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2dbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import boto3\n",
    "\n",
    "# Initialize a boto3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Define S3 bucket and path\n",
    "s3_bucket = \"pgx-repository\"\n",
    "drug_name_s3_path = f\"ade-risk-model/Step3_Normalize_Drug_Name/drug_names_cleaned_{cohort}.csv\"\n",
    "\n",
    "# Create a buffer\n",
    "csv_buffer = BytesIO()\n",
    "unique_drug_names.to_csv(csv_buffer, index=False)\n",
    "csv_buffer.seek(0)\n",
    "\n",
    "# Upload the buffer\n",
    "s3_client.upload_fileobj(\n",
    "    csv_buffer,\n",
    "    s3_bucket,\n",
    "    drug_name_s3_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = clean_df.filter((col(\"year\") >= 2016) & (col(\"year\") <= 2018)).distinct()\n",
    "test_df = clean_df.filter(col(\"year\") == 2019).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98612674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distinct mi_person_keys from both datasets\n",
    "train_keys = train_df.select(\"mi_person_key\").distinct()\n",
    "test_keys = test_df.select(\"mi_person_key\").distinct()\n",
    "\n",
    "# Check for overlapping keys using a left anti join\n",
    "overlap_keys = train_keys.join(test_keys, train_keys.mi_person_key == test_keys.mi_person_key, \"left_anti\")\n",
    "\n",
    "# Count to see if there are any overlapping keys\n",
    "overlap_count = overlap_keys.count()\n",
    "\n",
    "if overlap_count == 0:\n",
    "    print(\"No overlapping mi_person_keys between train and test datasets.\")\n",
    "else:\n",
    "    print(f\"Warning: There are {overlap_count} overlapping mi_person_keys between train and test datasets.\")\n",
    "    # Remove overlapping mi_person_keys from the test dataset using a left anti join\n",
    "    test_df = test_df.join(train_keys, [\"mi_person_key\"], \"left_anti\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c34e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate and show hospitalization counts for both dataframes\n",
    "def count_values(df, column_name):\n",
    "    # Count the occurrences of each value in the specified column\n",
    "    count_df = df.groupBy(column_name).count()\n",
    "    # Show the result\n",
    "    count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Counts for Training Dataset:\")\n",
    "count_values(train_df, \"hospitalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Counts for Test Dataset:\")\n",
    "count_values(test_df, \"hospitalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a25ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a620e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Convert mi_person_key to string and select specific columns for train and test sets\n",
    "test_df = test_df.select(\n",
    "    col(\"mi_person_key\").cast(\"string\").alias(\"mi_person_key\"),\n",
    "    \"drug_date\",\n",
    "    \"standardized_drug_name\",\n",
    "    \"Hospitalization\"\n",
    ")\n",
    "\n",
    "train_df = train_df.select(\n",
    "    col(\"mi_person_key\").cast(\"string\").alias(\"mi_person_key\"),\n",
    "    \"drug_date\",\n",
    "    \"standardized_drug_name\",\n",
    "    \"Hospitalization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.withColumnRenamed(\"Hospitalization\", \"label\")\n",
    "test_df = test_df.withColumnRenamed(\"Hospitalization\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train DataFrame Schema:\")\n",
    "train_df.printSchema()\n",
    "print(\"\\nTest DataFrame Schema:\")\n",
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for saving datasets to S3\n",
    "s3_bucket = \"s3://pgx-repository/ade-risk-model/Step5_Time_to_Event_Model/1_input_datasets/{cohort}\"\n",
    "train_output_path = f\"{s3_bucket}/train\"\n",
    "test_output_path = f\"{s3_bucket}/test\"\n",
    "\n",
    "# Save train and test DataFrames to S3 in Parquet format\n",
    "train_df.write.mode(\"overwrite\").parquet(train_output_path)\n",
    "test_df.write.mode(\"overwrite\").parquet(test_output_path)\n",
    "\n",
    "print(f\"Train dataset saved to {train_output_path}\")\n",
    "print(f\"Test dataset saved to {test_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Step 1: StringIndexer for mi_person_key (categorical feature)\n",
    "person_key_indexer = StringIndexer(inputCol=\"mi_person_key\", outputCol=\"person_key_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Step 2: StringIndexer for standardized_drug_name\n",
    "drug_name_indexer = StringIndexer(inputCol=\"standardized_drug_name\", outputCol=\"drug_name_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Step 3: OneHotEncoder for drug_name_index (leave mi_person_key as indexed)\n",
    "one_hot_encoder = OneHotEncoder(inputCol=\"drug_name_index\", outputCol=\"drug_name_one_hot\")\n",
    "\n",
    "# Step 4: VectorAssembler to combine features (include person_key_index)\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"person_key_index\", \"drug_name_one_hot\"],  # Include mi_person_key as an indexed categorical feature\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[person_key_indexer, drug_name_indexer, one_hot_encoder, assembler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c892ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "# Transform the dataset\n",
    "processed_train_df = pipeline_model.transform(train_df)\n",
    "processed_test_df = pipeline_model.transform(test_df)\n",
    "\n",
    "# Inspect the transformed DataFrame\n",
    "processed_train_df.select(\"mi_person_key\", \"person_key_index\", \"standardized_drug_name\", \"drug_name_index\", \"drug_name_one_hot\", \"features\", \"label\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Pool objects\n",
    "train_pool = catboost_spark.Pool(processed_train_df.select(\"features\", \"label\"))\n",
    "\n",
    "test_pool = catboost_spark.Pool(processed_test_df.select(\"features\", \"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fae0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "# Paths for saving processed datasets to S3\n",
    "s3_bucket = \"s3://pgx-repository/ade-risk-model/Step5_Time_to_Event_Model/2_processed_datasets/{cohort}\"\n",
    "processed_train_output_path = f\"{s3_bucket}/train\"\n",
    "processed_test_output_path = f\"{s3_bucket}/test\"\n",
    "feature_info_path = f\"{s3_bucket}/feature_info_{cohort}.json\"\n",
    "\n",
    "# Save train and test DataFrames to S3 in Parquet format\n",
    "processed_train_df.write.mode(\"overwrite\").parquet(processed_train_output_path)\n",
    "processed_test_df.write.mode(\"overwrite\").parquet(processed_test_output_path)\n",
    "\n",
    "print(f\"Processed Train dataset saved to {processed_train_output_path}\")\n",
    "print(f\"Processed Test dataset saved to {processed_test_output_path}\")\n",
    "\n",
    "# Extract feature names from StringIndexer\n",
    "index_to_category = {i: category for i, category in enumerate(pipeline_model.stages[1].labels)}\n",
    "feature_names = [\n",
    "    f\"{category} | drug_name_index_{i}\"  # Use a separator (e.g., ->) here\n",
    "    for i, category in index_to_category.items()\n",
    "]\n",
    "\n",
    "# Save feature names and types\n",
    "feature_info = {\n",
    "    \"names\": feature_names,\n",
    "    \"types\": \"one-hot encoded vector\",\n",
    "    \"source_column\": \"drug_name\"\n",
    "}\n",
    "\n",
    "# Save the JSON to S3 using an in-memory buffer\n",
    "bucket_name = s3_bucket.split('/')[2]\n",
    "s3_key = \"/\".join(s3_bucket.split('/')[3:]) + f\"/feature_info_{cohort}.json\"\n",
    "\n",
    "buffer = io.BytesIO()\n",
    "buffer.write(json.dumps(feature_info, indent=4).encode('utf-8'))\n",
    "buffer.seek(0)\n",
    "\n",
    "s3_client.upload_fileobj(buffer, bucket_name, s3_key)\n",
    "\n",
    "print(f\"Feature information for {cohort} saved to {feature_info_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c11d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
