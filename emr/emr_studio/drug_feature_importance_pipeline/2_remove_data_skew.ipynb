{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5dedf-e7c6-476d-a86e-34eb13b5f870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.broadcast.compress\": \"true\", \n",
    "        \"spark.jars.packages\": \"ai.catboost:catboost-spark_3.5_2.12:1.2.7\",\n",
    "        \"spark.jars.packages.resolve.transitive\": \"true\",\n",
    "        \"spark.executor.memory\": \"180g\",\n",
    "        \"spark.executor.cores\": \"1\",   \n",
    "        \"spark.executorEnv.CATBOOST_WORKER_INIT_TIMEOUT\": \"3600s\",\n",
    "        \"spark.executor.extraJavaOptions\": \"--add-exports java.base/sun.net.util=ALL-UNNAMED\",\n",
    "        \"spark.executor.memoryOverhead\": \"8g\",\n",
    "        \"spark.driver.extraJavaOptions\": \"--add-exports java.base/sun.net.util=ALL-UNNAMED\",\n",
    "        \"spark.driver.memory\": \"45g\",          \n",
    "        \"spark.dynamicAllocation.enabled\": \"true\",\n",
    "        \"spark.dynamicAllocation.minExecutors\": \"2\",\n",
    "        \"spark.dynamicAllocation.maxExecutors\": \"103\",     \n",
    "        \"spark.network.timeout\": \"1200s\",  \n",
    "        \"spark.rpc.askTimeout\": \"1200s\", \n",
    "        \"spark.rpc.message.maxSize\": \"512\",\n",
    "        \"spark.sql.broadcastTimeout\": \"1200s\",\n",
    "        \"spark.sql.session.timeout\": \"1200s\",\n",
    "        \"spark.sql.shuffle.partitions\": \"103\",\n",
    "        \"spark.sql.autoBroadcastJoinThreshold\": \"-1\",\n",
    "        \"spark.shuffle.service.enabled\": \"true\",\n",
    "        \"spark.task.cpus\": \"1\",  \n",
    "        \"spark.yarn.am.memory\": \"45g\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04fa74-e410-455e-ba84-919cbeefe66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
    "import catboost_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7407cc-8efe-4fe0-8003-0a06d020be06",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Adding a parameter tag\n",
    "cohort = 'cohort6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe237a-df8a-47fe-805d-1c91368c5f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3 Paths\n",
    "s3_bucket = f\"s3://pgx-repository/ade-risk-model/Step5_Time_to_Event_Model/2_processed_datasets/{cohort}\"\n",
    "train_input_path = f\"{s3_bucket}/train\"\n",
    "test_input_path = f\"{s3_bucket}/test\"\n",
    "\n",
    "# Read processed train and test datasets from S3\n",
    "print(\"Reading train and test datasets...\")\n",
    "train_df = spark.read.parquet(train_input_path)\n",
    "test_df = spark.read.parquet(test_input_path)\n",
    "\n",
    "print(\"Train and test datasets successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b8757-0c37-4dc0-9337-410dc9616c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify output\n",
    "print(\"Train Dataframe Schema:\")\n",
    "train_df.printSchema()\n",
    "print(\"Test Dataframe Schema:\")\n",
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2bea9b-6724-4712-a588-15029614c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Step 1: Compute Features\n",
    "polypharmacy_df = df.groupBy(\"mi_person_key\").agg(\n",
    "    F.countDistinct(\"drug_name\").alias(\"polypharmacy\")\n",
    ")\n",
    "\n",
    "activity_count_df = df.groupBy(\"mi_person_key\").agg(\n",
    "    F.count(\"*\").alias(\"activity_count\")\n",
    ")\n",
    "\n",
    "# Add computed features to the main DataFrame\n",
    "enhanced_df = df.join(polypharmacy_df, on=\"mi_person_key\", how=\"left\") \\\n",
    "                .join(activity_count_df, on=\"mi_person_key\", how=\"left\")\n",
    "\n",
    "# Step 2: Create Polypharmacy and Activity Count Bins\n",
    "enhanced_df = enhanced_df.withColumn(\n",
    "    \"polypharmacy_bin\",\n",
    "    F.when(F.col(\"polypharmacy\") <= 5, \"low\")\n",
    "     .when((F.col(\"polypharmacy\") > 5) & (F.col(\"polypharmacy\") <= 10), \"medium\")\n",
    "     .otherwise(\"high\")\n",
    ").withColumn(\n",
    "    \"activity_count_bin\",\n",
    "    F.when(F.col(\"activity_count\") <= 50, \"low\")\n",
    "     .when((F.col(\"activity_count\") > 50) & (F.col(\"activity_count\") <= 200), \"medium\")\n",
    "     .otherwise(\"high\")\n",
    ")\n",
    "\n",
    "# Step 3: Add a Hash Partition Column\n",
    "enhanced_df = enhanced_df.withColumn(\n",
    "    \"hash_partition\", F.abs(F.hash(\"mi_person_key\")) % 103  # Distributes evenly across 103 partitions\n",
    ")\n",
    "\n",
    "# Step 4: Repartition the Data\n",
    "partitioned_df = enhanced_df.repartition(103, \"hash_partition\", \"polypharmacy_bin\", \"mi_person_key\")\n",
    "\n",
    "# Step 5: Create CatBoost Pool\n",
    "train_pool = catboost_spark.Pool(partitioned_df.select(\"features\", \"label\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe3820-8c8b-41a2-a92d-3331f7086a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CatBoost Pool objects\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "# Cache or persist the Spark DataFrames before creating the Pool\n",
    "train_df = train_df.select(\"features\", \"label\").persist(StorageLevel.MEMORY_AND_DISK)\n",
    "test_df = test_df.select(\"features\", \"label\").persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# Create the CatBoost Pool objects\n",
    "train_pool = catboost_spark.Pool(train_df)\n",
    "test_pool = catboost_spark.Pool(test_df)\n",
    "\n",
    "# Confirm the DataFrames are cached/persisted\n",
    "print(train_df.storageLevel)\n",
    "print(test_df.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b8922-5a40-4728-ac0c-7803e78f49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.unpersist()\n",
    "test_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994ae6d-b4ba-4622-9bcb-cc119f29e502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a01636119c44ea28ebc581481e89a45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "max_height": "500px",
       "overflow_y": "scroll"
      }
     },
     "3bd949c37ddd4d48baaae20936dd6fc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "AccordionModel",
      "state": {
       "_titles": {
        "0": "Spark Job Progress"
       },
       "children": [
        "IPY_MODEL_cd1e41387a694a46bc0feb3bc43b740e"
       ],
       "layout": "IPY_MODEL_7d4b92517e9b44c6969566f46f1867d9",
       "selected_index": null
      }
     },
     "4682619abf6741158e0833cb191ba05c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "layout": "IPY_MODEL_0a01636119c44ea28ebc581481e89a45"
      }
     },
     "566fd5d0063e43e680c50fbb4a863d3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "layout": "IPY_MODEL_fa059ada50bd44f0abfd975d70325ef1"
      }
     },
     "7d4b92517e9b44c6969566f46f1867d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9f84776f493a44eea35a4dd51f233853": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cd1e41387a694a46bc0feb3bc43b740e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4682619abf6741158e0833cb191ba05c"
       ],
       "layout": "IPY_MODEL_9f84776f493a44eea35a4dd51f233853"
      }
     },
     "fa059ada50bd44f0abfd975d70325ef1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
