%%configure -f
{
    "conf": {
        "spark.jars.packages": "ai.catboost:catboost-spark_3.5_2.12:1.2.7",
        "spark.executor.memory": "24g",
        "spark.executor.cores": "4",       
        "spark.driver.memory": "24g",      
        "spark.yarn.am.memory": "4g",     
        "spark.dynamicAllocation.enabled": "true", 
        "spark.task.cpus": "4",          
        "spark.jars.packages.resolve.transitive": "true",
        "spark.executor.extraJavaOptions": "--add-exports java.base/sun.net.util=ALL-UNNAMED",
        "spark.driver.extraJavaOptions": "--add-exports java.base/sun.net.util=ALL-UNNAMED",
        "spark.network.timeout": "1200s",  
        "spark.rpc.askTimeout": "1200s", 
        "spark.executor.memoryOverhead": "4g"
    }
}





val spark = SparkSession.builder().
  appName("Evaluate CatBoost Model").
  config("spark.jars.packages", ""ai.catboost:catboost-spark_3.5_2.12:1.2.7").
  config("spark.jars.packages.resolve.transitive", "true").
  config("spark.executor.memory", "24g").
  config("spark.executor.memoryOverhead", "4g").
  config("spark.executor.cores", "4").
  config("spark.task.cpus", "4").
  config("spark.driver.memory", "24g").
  config("spark.yarn.am.memory", "4g").
  config("spark.dynamicAllocation.enabled", "true").
  config("spark.executor.extraJavaOptions", "--add-exports java.base/sun.net.util=ALL-UNNAMED").
  config("spark.driver.extraJavaOptions", "--add-exports java.base/sun.net.util=ALL-UNNAMED").
  config("spark.network.timeout", "1200s").
  config("spark.rpc.askTImeout", "1200s").
  getOrCreate()
  
  
  
  val spark = SparkSession.builder().
  appName("Evaluate CatBoost Model").
  config("spark.jars.packages", "ai.catboost:catboost-spark_3.5_2.12:1.2.7").
  config("spark.jars.packages.resolve.transitive", "true").
  config("spark.executor.memory", "36g").  // Adjusted executor memory
  config("spark.executor.memoryOverhead", "8g").  // Increased overhead
  config("spark.executor.cores", "8").  // Increased cores per executor
  config("spark.task.cpus", "8").  // Tasks will match cores per executor
  config("spark.driver.memory", "36g").  // Adjusted for the driver
  config("spark.yarn.am.memory", "8g").  // Adjusted for YARN application master
  config("spark.dynamicAllocation.enabled", "true").
  config("spark.dynamicAllocation.minExecutors", "1").
  config("spark.dynamicAllocation.maxExecutors", "5").  // Utilize cluster scale
  config("spark.executor.extraJavaOptions", "--add-exports java.base/sun.net.util=ALL-UNNAMED").
  config("spark.driver.extraJavaOptions", "--add-exports java.base/sun.net.util=ALL-UNNAMED").
  config("spark.network.timeout", "1200s").
  config("spark.rpc.askTimeout", "1200s").
  config("spark.sql.shuffle.partitions", "200").  // Adjusted for large data
  getOrCreate()
